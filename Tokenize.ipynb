{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ccef61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Words:\n",
      "['Artificial', 'intelligence', 'is', 'transforming', 'industries', 'across', 'the', 'globe', '.', 'From', 'healthcare', 'to', 'finance', ',', 'AI-powered', 'systems', 'are', 'enabling', 'faster', ',', 'more', 'accurate', 'decisions', '.', 'As', 'this', 'technology', 'continues', 'to', 'evolve', ',', 'its', 'impact', 'on', 'society', 'is', 'expected', 'to', 'grow', 'even', 'further', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jesli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "paragraph = \"Artificial intelligence is transforming industries across the globe. From healthcare to finance, AI-powered systems are enabling faster, more accurate decisions. As this technology continues to evolve, its impact on society is expected to grow even further.\"\n",
    "\n",
    "words = word_tokenize(paragraph)\n",
    "\n",
    "print(\"Tokenized Words:\")\n",
    "print(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10fb732a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artificial intelligence is transforming industries across the globe from healthcare to finance aipowered systems are enabling faster more accurate decisions as this technology continues to evolve its impact on society is expected to grow even further\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "paragraph_clean = ''.join(char.lower() for char in paragraph if char not in string.punctuation)\n",
    "print(paragraph_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ce0d3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jesli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\jesli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Words:\n",
      "['artifici', 'intellig', 'is', 'transform', 'industri', 'across', 'the', 'globe', '.', 'from', 'healthcar', 'to', 'financ', ',', 'ai-pow', 'system', 'are', 'enabl', 'faster', ',', 'more', 'accur', 'decis', '.', 'as', 'thi', 'technolog', 'continu', 'to', 'evolv', ',', 'it', 'impact', 'on', 'societi', 'is', 'expect', 'to', 'grow', 'even', 'further', '.']\n",
      "Lemmatized Words:\n",
      "['Artificial', 'intelligence', 'is', 'transforming', 'industry', 'across', 'the', 'globe', '.', 'From', 'healthcare', 'to', 'finance', ',', 'AI-powered', 'system', 'are', 'enabling', 'faster', ',', 'more', 'accurate', 'decision', '.', 'As', 'this', 'technology', 'continues', 'to', 'evolve', ',', 'it', 'impact', 'on', 'society', 'is', 'expected', 'to', 'grow', 'even', 'further', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in words]\n",
    "print(\"Stemmed Words:\")\n",
    "print(stemmed_words)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "print(\"Lemmatized Words:\")\n",
    "print(lemmatized_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vgg16_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
