{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9771587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesli\\.conda\\envs\\vgg16_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the Hindi model for Stanza...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.11.0.json: 435kB [00:00, 26.2MB/s]                    \n",
      "2025-10-15 15:11:17 INFO: Downloaded file to C:\\Users\\jesli\\stanza_resources\\resources.json\n",
      "2025-10-15 15:11:17 INFO: Downloading default packages for language: hi (Hindi) ...\n",
      "2025-10-15 15:11:18 INFO: File exists: C:\\Users\\jesli\\stanza_resources\\hi\\default.zip\n",
      "2025-10-15 15:11:20 INFO: Finished downloading models and saved to C:\\Users\\jesli\\stanza_resources\n",
      "2025-10-15 15:11:20 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing the Hindi pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.11.0.json: 435kB [00:00, 21.4MB/s]                    \n",
      "2025-10-15 15:11:20 INFO: Downloaded file to C:\\Users\\jesli\\stanza_resources\\resources.json\n",
      "2025-10-15 15:11:21 INFO: Loading these models for language: hi (Hindi):\n",
      "=============================\n",
      "| Processor | Package       |\n",
      "-----------------------------\n",
      "| tokenize  | hdtb          |\n",
      "| pos       | hdtb_charlm   |\n",
      "| lemma     | hdtb_nocharlm |\n",
      "| depparse  | hdtb_charlm   |\n",
      "| ner       | ilner_charlm  |\n",
      "=============================\n",
      "\n",
      "2025-10-15 15:11:23 INFO: Using device: cuda\n",
      "2025-10-15 15:11:23 INFO: Loading: tokenize\n",
      "2025-10-15 15:11:24 INFO: Loading: pos\n",
      "2025-10-15 15:11:27 INFO: Loading: lemma\n",
      "2025-10-15 15:11:28 INFO: Loading: depparse\n",
      "2025-10-15 15:11:28 INFO: Loading: ner\n",
      "2025-10-15 15:11:31 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "# Download the Hindi model\n",
    "# This will download the model to a 'stanza_resources' directory in your home folder.\n",
    "print(\"Downloading the Hindi model for Stanza...\\n\")\n",
    "stanza.download('hi')\n",
    "\n",
    "# Initialize the Hindi pipeline\n",
    "print(\"\\nInitializing the Hindi pipeline...\")\n",
    "nlp = stanza.Pipeline('hi')\n",
    "print(\"Pipeline initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deb9de42",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_sentences = [\n",
    "    \"राम एक अच्छा लड़का है।\",\n",
    "    \"वह मुंबई में रहता है।\",\n",
    "    \"मैंने आज एक नई किताब खरीदी।\",\n",
    "    \"भारत की राजधानी दिल्ली है।\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "952a36a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sentence 1: 'राम एक अच्छा लड़का है।' ---\n",
      "Word            POS Tag   \n",
      "-------------------------\n",
      "राम             PROPN     \n",
      "एक              NUM       \n",
      "अच्छा           ADJ       \n",
      "लड़का           NOUN      \n",
      "है              AUX       \n",
      "।               PUNCT     \n",
      "\n",
      "\n",
      "--- Sentence 2: 'वह मुंबई में रहता है।' ---\n",
      "Word            POS Tag   \n",
      "-------------------------\n",
      "वह              PRON      \n",
      "मुंबई           PROPN     \n",
      "में             ADP       \n",
      "रहता            VERB      \n",
      "है              AUX       \n",
      "।               PUNCT     \n",
      "\n",
      "\n",
      "--- Sentence 3: 'मैंने आज एक नई किताब खरीदी।' ---\n",
      "Word            POS Tag   \n",
      "-------------------------\n",
      "मैंने           PRON      \n",
      "आज              NOUN      \n",
      "एक              NUM       \n",
      "नई              ADJ       \n",
      "किताब           NOUN      \n",
      "खरीदी           VERB      \n",
      "।               PUNCT     \n",
      "\n",
      "\n",
      "--- Sentence 4: 'भारत की राजधानी दिल्ली है।' ---\n",
      "Word            POS Tag   \n",
      "-------------------------\n",
      "भारत            PROPN     \n",
      "की              ADP       \n",
      "राजधानी         NOUN      \n",
      "दिल्ली          PROPN     \n",
      "है              AUX       \n",
      "।               PUNCT     \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(hindi_sentences):\n",
    "    print(f\"--- Sentence {i+1}: '{sentence}' ---\")\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    for sent in doc.sentences:\n",
    "        print(\"{:<15} {:<10}\".format('Word', 'POS Tag'))\n",
    "        print(\"-\"*25)\n",
    "        for word in sent.words:\n",
    "            print(f\"{word.text:<15} {word.upos:<10}\")\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vgg16_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
